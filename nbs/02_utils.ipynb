{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "from pulsepoint.core import *\n",
    "from typing import Union, Callable\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filterting Input Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to be able to filter the input data to fit our testing needs. `_filter_dataframe` is a function to do this that takes in a pandas Dataframe and a set of filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _filter_dataframe(df,     # A pandas DataFrame\n",
    "                     filters, # dictonary or list of dictionaries\n",
    "                     )-> pd.DataFrame:\n",
    "    \"\"\"Filter a DataFrame using a dictionary or a list of dictionaries with multiple filter conditions.\n",
    "    \n",
    "    Filter Examples:\n",
    "    You can pass in a single value like {\"State\":\"Wisconsin\"}.\n",
    "    You can also pass in a list {\"Cities\":[\"La Crosse\",\"Madison\",\"Eau Claire\",\"Milwaukee\"]}\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(filters, dict): filters = [filters]\n",
    "    \n",
    "    for filter_dict in filters:\n",
    "        for column, value in filter_dict.items():\n",
    "\n",
    "            if isinstance(value, list):      df = df[df[column].isin(value)]\n",
    "            else:                            df = df[df[column] == value]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Dimensions with few Observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _rm_small_dims(df,threshold:int):\n",
    "    \"\"\"Remove Dimensions that have less than N observations\"\"\"\n",
    "    val_drop = list(df['unique_id'].value_counts()[df['unique_id'].value_counts() < threshold].index)\n",
    "    df = df[~df['unique_id'].isin(val_drop)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Names and Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def _name_type_check(df,dimension,date_col):\n",
    "    \"\"\"Check datatypes and names of columns\"\"\"\n",
    "    if dimension: \n",
    "        df = df.rename(columns={date_col: 'ds', dimension: 'unique_id'})\n",
    "    else:\n",
    "        df = df.rename(columns={date_col: 'ds'})\n",
    "        df['unique_id'] = 'Total'\n",
    "    \n",
    "    if df['y'].dtype != 'float64': df['y'] = df['y'].astype(float)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Metric Column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def _process_metric_col(df,metric_col):\n",
    "\n",
    "    if callable(metric_col): df['y'] = metric_col(grpd_df)\n",
    "    else:\n",
    "        if metric_col in df.columns: df = df.rename(columns={metric_col: 'y'})\n",
    "        else: raise ValueError(f\"metric_col '{metric_col}' not found in the dataframe columns.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting Everthing together: `_process_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def _process_data(\n",
    "    path: str, \n",
    "    dimension: str = None,\n",
    "    date_col: str = 'ds', \n",
    "    metric_col: Union[str, Callable] = 'y',\n",
    "    filters: list[dict] = None,\n",
    "    sz_threshold = 50):\n",
    "    \"\"\"Filters and aggregates data\"\"\"\n",
    "\n",
    "    df = pd.read_feather(path)\n",
    "    \n",
    "    if dimension and isinstance(dimension, str): idxs = [dimension, date_col]\n",
    "    else:                                        idxs = [date_col]\n",
    "\n",
    "    if filters: df = _filter_dataframe(df, filters)\n",
    "\n",
    "    num_cols = list(df.select_dtypes(include=['int64', 'float64', 'int32', 'float32']).columns)\n",
    "\n",
    "    if len(num_cols) == 0: raise ValueError(f\"No numerical columns found. \\nThe {metric_col} column(s) should be of type int or float\")\n",
    "\n",
    "    grpd_df = pd.pivot_table(df, values=num_cols, index=idxs, aggfunc='sum').reset_index()\n",
    "    agg_df = _process_metric_col(grpd_df, metric_col) \n",
    "    fnl_df = _name_type_check(agg_df,dimension,date_col)\n",
    "    fnl_df = _rm_small_dims(fnl_df,sz_threshold)\n",
    "\n",
    "    return fnl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
